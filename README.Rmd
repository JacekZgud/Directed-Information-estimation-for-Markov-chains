---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# Markov.dir.info

<!-- badges: start -->
<!-- badges: end -->

The goal of this collection is to simulate the specific class of Markov chains and calculate relevant information theory-based measures. The code is oriented around `MarkovProcess` S4 class object.
## Installation

You can install the development version of Markov.dir.info like so:

``` r
install_github("JacekZgud/Directed-Information-estimation-for-Markov-chains")
```

### Comparison to Ay Polani information flow using an example from their article.
Script for it may be found in `mutual_info_comparison.R` followed by some other visualisations.


## Example

This is a basic example which shows you how to use the library:

```{r example,message=FALSE}
library(Markov.dir.info)
## basic example code

# parametrise the code
node_dim = 3
nodes = 3
work_names = tail(LETTERS, nodes)

#define parent structure
ParentStructure = matrix(nrow = nodes, ncol = nodes, data = 0)
rownames(ParentStructure) = colnames(ParentStructure) = work_names

# define the parent structure of nodes
diag(ParentStructure) = 1
ParentStructure[2, 3] = 1
ParentStructure[3, 2] = 1
ParentStructure[1, 2] = 1
ParentStructure[2, 1] = 1

#------------------------------------------------------------------------
#initialize class for markov_simulations
process = MarkovProcess(node_dim, nodes, ParentStructure, work_names)
process@trans_prob

#example of quick manual conditional probability changes:

process2 = MarkovProcess(node_dim, nodes, ParentStructure, work_names)
process2@trans_prob$X$prob_0 = c(0.05, 0.05, 0.90, 0.90, 0.05, 0.05, 0.90, 0.90, 0.1)
process2@trans_prob$X$prob_1 = c(0.90, 0.90, 0.05, 0.05, 0.90, 0.90, 0.05, 0.05, 0.1)
process2@trans_prob$X$prob_2 = 1 - process@trans_prob$X$prob_1 -  process@trans_prob$X$prob_0
process2@trans_prob$X



#------------------------------------------------------------------------
#transition matrix
#takes some time to calculate, approx 30 sec for n=3 and d=4.

process = stationary.probability(process)

process = trans.matrix(process)

#------------------------------------------------------------------------
#markov process simulation
#m=10^7
m = 10 ^ 2

process = simulate(process, m)
process@simulation

#-------------------------------------------------------------------------
# simulate marginalized markov process
n_2 = 10 ^ 2

process = simulate.marginalized(process, c('Y', 'Z'), n_2)

process@marg_sim

#calculate transfer entropy from V/target -----> target
process = trans_entropy(process, c('Y', 'Z'), sim.length = n_2)

```



